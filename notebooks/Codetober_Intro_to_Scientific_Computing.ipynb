{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3f73cd",
   "metadata": {},
   "source": [
    "# Codetober. II: Scientific Computing in Python\n",
    "Session leader: Matthew Lundy (matthew.lundy@mail.mcgill.ca)\n",
    "\n",
    "Notebook Author: Jordan Mirocha (jordan.mirocha@mcgill.ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ebb4d8",
   "metadata": {},
   "source": [
    "**Welcome!** \n",
    "\n",
    "Before we start, be sure to download the data we'll use today:\n",
    "\n",
    "https://www.kaggle.com/aubertsigouin/biximtl/download\n",
    "\n",
    "This should download a file called `archive.zip`. Once finished, I'd recommend making a new folder for today's session, e.g.,:\n",
    "\n",
    "```text\n",
    "cd ~/Desktop\n",
    "mkdir codetober_2\n",
    "cd codetober_2\n",
    "mv ~/Downloads/archive.zip .\n",
    "unzip archive.zip\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33bbaa",
   "metadata": {},
   "source": [
    "#### it will also be convenient if you copy this notebook into that new folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a053c",
   "metadata": {},
   "source": [
    "## So...what is *scientific* computing?\n",
    "\n",
    "When people emphasize that something is *scientific* computing, as opposed to just *computing* computing, they generally mean that the computations in question allow us to better understand natural systems through data analysis and modeling techniques that would be impossible to execute by hand. The data here is assumed to be numerical, and we operate on this data (or create it) with algorithms whose fundamental language is mathematics.\n",
    "\n",
    "In other words, it's computing that helps us do science better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b48c0",
   "metadata": {},
   "source": [
    "### Scope\n",
    "\n",
    "This is a big topic -- we'll only scratch the surface in the next 1.5 hours. With that in mind, **the goal is to touch on the tools and techniques you're most likely to need when you first get involved with research**, to help ease that transition. But, I'll also sprinkle in some tricks of the trade that will be useful as you start to build more sophisticated software, so if you already have some research experience, this workshop should still be worth your while.\n",
    "\n",
    "No prior experience with Python or scientific computing is necessary!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08919673",
   "metadata": {},
   "source": [
    "### Plan for today \n",
    "\n",
    "There are many fantastic resources online for learning Python, some of which I'll draw upon here (e.g., [arrays](https://github.com/profjsb/python-bootcamp/blob/master/Lectures/21_NumpyMatplotlib/IntroNumPy.ipynb), [plotting](https://github.com/profjsb/python-bootcamp/blob/master/Lectures/21_NumpyMatplotlib/IntroMatplolib.ipynb)), scientific computing techniques, etc.\n",
    "\n",
    "BUT, my biggest complaint about a lot of online tutorials is that there is not very much context. It's a lot of trying to learn/memorize Python syntax without any reasoning for why knowing these things is good.\n",
    "\n",
    "So, today we're going to get our hands dirty with some publicly available [BIXI data](https://www.kaggle.com/aubertsigouin/biximtl). Just by \"playing with\" this data and asking simple questions about it, we will learn:\n",
    "\n",
    "- How to read and write basic data files (very common)\n",
    "- How to find interesting parts of datasets that are too big to sift through entirely by eye.\n",
    "- How to slice and dice the data to do interesting analyses.\n",
    "- How to plot data, including time series, images, and histograms.\n",
    "- How to do some simple model fitting.\n",
    "\n",
    "Here's [an example](https://towardsdatascience.com/understanding-bixi-commuters-an-analysis-of-montreals-bike-share-system-in-python-cb34de0e2304) of what other people are doing with this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f0b9e",
   "metadata": {},
   "source": [
    "## Disclaimer! I don't know anything about transportation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef69ffb",
   "metadata": {},
   "source": [
    "## Getting started: imports and key packages\n",
    "\n",
    "Your new best friends: `numpy` and `matplotlib`. We'll talk about `scipy` later too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d4870",
   "metadata": {},
   "source": [
    "`numpy` is short for \"numerical Python\". It allows us to create and manipulate *arrays*, which are like lists or tuples, but are designed to contain a single data type (generally integers or floats). Unlike lists, we can perform mathematical operations on arrays, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [1,2,3,4]\n",
    "my_array = np.arange(1, 5)\n",
    "print(my_list * 2, my_array * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa30bd",
   "metadata": {},
   "source": [
    "Multiplying lists by an integer $N$ creates a new list containing the same elements repeated $N$ times! \n",
    "\n",
    "Multiplying an array by a number $N$ yields the more intuitive result, in which each entry is multiplied by $N$. In other words, the operation is performed \"element-wise,\" i.e., element by element.\n",
    "\n",
    "You can reproduce what `numpy` does using `for` loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4492398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for element in my_list:\n",
    "    new_list.append(2 * element)\n",
    "    \n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db248d5c",
   "metadata": {},
   "source": [
    "However, this is *a lot* slower than the equivalent operation in `numpy`, especially for really big arrays. This is because `numpy` is really a wrapper around compiled C code.\n",
    "\n",
    "**In scientific computing, avoid using loops at all costs!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431cbd1",
   "metadata": {},
   "source": [
    "## Reading in the BIXI data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae0068",
   "metadata": {},
   "source": [
    "Hopefully, anytime you download a dataset there's some README file that tells you how the data is structured. However, in this case, the data is a human-readable format, so we can just glance at it to see what's in there. If you open it in a text editor, or look at it on the command line via `less`, it should look something like:\n",
    "\n",
    "```text\n",
    ",start_date,start_station_code,end_date,end_station_code,duration_sec,is_member\n",
    "0,2014-04-15 00:01,6209,2014-04-15 00:18,6436,1061,1\n",
    "1,2014-04-15 00:01,6214,2014-04-15 00:11,6248,615,1\n",
    "2,2014-04-15 00:01,6164,2014-04-15 00:18,6216,1031,1\n",
    "3,2014-04-15 00:01,6214,2014-04-15 00:24,6082,1382,1\n",
    "4,2014-04-15 00:02,6149,2014-04-15 00:08,6265,347,1\n",
    "5,2014-04-15 00:05,6214,2014-04-15 00:08,6211,167,1\n",
    "```\n",
    "\n",
    "This is for the file `OD_2014.csv`. There are separate files for the station info, e.g., in `Stations_2014.csv` we have:\n",
    "\n",
    "```text\n",
    "code,name,latitude,longitude\n",
    "6209,Milton / Clark,45.51252,-73.57062\n",
    "6436,Côte St-Antoine / Clarke,45.48645209646392,-73.59523415565491\n",
    "6214,Square St-Louis,45.51735,-73.56906\n",
    "6248,St-Dominique / Rachel,45.518593,-73.581566\n",
    "6164,Chambord / Laurier,45.5329550401632,-73.58419418334961\n",
    "6216,Parc Jeanne Mance (monument George-Étienne Cartier),45.51496,-73.58503\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ccc63",
   "metadata": {},
   "source": [
    "`numpy` has a convenience routine called `loadtxt` to help read in tabular data like this. Let's give that a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath= 'C:/Users/matth/Desktop/codetober_2/' #change based on your username/file location. If your notebook is in the same folder\n",
    "#you can set this to ''\n",
    "data_2014 = np.loadtxt(filepath+'OD_2014.csv', delimiter=',', usecols=[0,5], skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656bcd2",
   "metadata": {},
   "source": [
    "#### Q. How many BIXI rides in 2014?\n",
    "Can determine just from the shape of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86eceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(data_2014))\n",
    "print(data_2014.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0143113d",
   "metadata": {},
   "source": [
    "#### Q. Has ridership increased over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2017 = np.loadtxt(filepath+'OD_2017.csv', delimiter=',', usecols=[0,5], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0015246",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_2017.shape[0] / float(data_2014.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a2add6",
   "metadata": {},
   "source": [
    "#### Q. Did the number of stations change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_2014 = np.loadtxt(filepath+'Stations_2014.csv', delimiter=',', usecols=[0], skiprows=1)\n",
    "stat_2017 = np.loadtxt(filepath+'Stations_2017.csv', delimiter=',', usecols=[0], skiprows=1)\n",
    "print(stat_2017.shape[0] / float(stat_2014.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91658ec7",
   "metadata": {},
   "source": [
    "#### How long was the typical ride in 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ride times to minutes\n",
    "duration_min_2014 = data_2014[:,1] / 60.\n",
    "\n",
    "# Compute mean\n",
    "mean_ride_2014 = np.mean(duration_min_2014)\n",
    "\n",
    "#Compute median\n",
    "\n",
    "median_ride_2014 = np.median(duration_min_2014)\n",
    "\n",
    "# Compute the mode\n",
    "hist, bin_edges = np.histogram(duration_min_2014, bins=100)\n",
    "mode_ride_2014 = bin_edges[hist.argmax()] \n",
    "# Note: this is a little sloppy: should take position of mode to be at bin *center*\n",
    "\n",
    "\n",
    "print(f'Mean ride = {mean_ride_2014:.2f}')\n",
    "print(f'Median ride = {median_ride_2014:.2f}')\n",
    "print(f'Mode of ride durations = {mode_ride_2014:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e71df5",
   "metadata": {},
   "source": [
    "#### How big of a spread is there in ride times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28430950",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "hist = pl.hist(duration_min_2014, bins=np.arange(1, 101), color='b', alpha=0.5)\n",
    "pl.axvline(mean_ride_2014, color='k', ls='--',label='Mean')\n",
    "pl.axvline(median_ride_2014, color='k', ls='dashdot',label='Median')\n",
    "pl.axvline(mode_ride_2014, color='k', ls=':',label='Mode')\n",
    "plt.legend()\n",
    "\n",
    "pl.xlabel('Ride duration [min]')\n",
    "pl.ylabel('Number of rides in 2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c452deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "hist = pl.hist(duration_min_2014, bins=np.arange(1, 101), color='b', alpha=0.5)\n",
    "pl.axvline(mean_ride_2014, color='k', ls='--',label='Mean')\n",
    "pl.axvline(median_ride_2014, color='k', ls='dashdot',label='Median')\n",
    "pl.axvline(mode_ride_2014, color='k', ls=':',label='Mode')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "pl.xlabel('Ride duration [min]')\n",
    "pl.ylabel('Number of rides in 2014')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf77797",
   "metadata": {},
   "source": [
    "## How to deal with dates in the dataset?\n",
    "\n",
    "One tricky thing about this dataset is that there is a mix of data types, which is going to cause problems for `numpy`, since each array needs to contain only variables of the same type!\n",
    "\n",
    "This is a great reason to use the `pandas` package, which has much more flexible file-reading machinery available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb89e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc67644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filepath+'OD_2014.csv')\n",
    "stations = pd.read_csv(filepath+'Stations_2014.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69249a0",
   "metadata": {},
   "source": [
    "Note that `data` and `stations` are now *objects*. Rather than slicing a pure `numpy` array, we access each column by name. To see what columns are available, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ce0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "print(stations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43286ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data['start_date'][0]\n",
    "date = datetime.datetime.strptime(s, \"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan1 = datetime.datetime(date.year, 1, 1, 0, 0)\n",
    "jan10 = datetime.datetime(date.year, 1, 10, 0, 0)\n",
    "diff = (jan10 - jan1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6011e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.__getattribute__('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'month', 'day', 'hour'\n",
    "start = {col:[] for col in cols}\n",
    "stop  = {col:[] for col in cols}\n",
    "duration = np.array([])\n",
    "subsamp=20\n",
    "for i in range(int(data.shape[0]/20)):\n",
    "    _start = datetime.datetime.strptime(data['start_date'][i], \"%Y-%m-%d %H:%M\")\n",
    "    _stop = datetime.datetime.strptime(data['end_date'][i], \"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    for col in cols:\n",
    "        start[col].append(_start.__getattribute__(col))\n",
    "        stop[col].append(_stop.__getattribute__(col))\n",
    "\n",
    "    diff = _stop - _start\n",
    "    duration=np.append(duration,diff.total_seconds()/60.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f551f7",
   "metadata": {},
   "source": [
    "#### Q. When do people ride most throughout the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c472fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "h = pl.hist(start['hour'], bins=np.arange(0, 25),edgecolor='black', linewidth=1.2)\n",
    "plt.xlabel('Time of Day (hour)')\n",
    "plt.ylabel('Number of trips')\n",
    "plt.xlim(0,24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ecb3c",
   "metadata": {},
   "source": [
    "#### Q. Are commutes longer than non-commutes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.arange(0, 24)\n",
    "oksum=0\n",
    "binconts=np.zeros(24)\n",
    "for i,hour in enumerate(hours):\n",
    "    ok = np.logical_and(start['hour'] >= hour, start['hour'] < hour+1)\n",
    "    binconts[i]=np.sum(duration[ok])/ok.sum()\n",
    "pl.figure(figsize=(15,7))\n",
    "plt.axvspan(6,9,color='darkred',alpha=0.5)\n",
    "plt.axvspan(15,18,color='darkred',alpha=0.5)\n",
    "pl.bar(hours+0.5,binconts,width=1,edgecolor='k',fill=False)\n",
    "pl.xlabel('Time of Day (hour)')\n",
    "plt.ylabel('Average ride duration')\n",
    "plt.xlim(0,24)\n",
    "plt.ylim(ymin=10)\n",
    "index=[6,7,8,15,16,17]\n",
    "print(f'Average time during rush hour : {np.mean(binconts[index]):.2f}')\n",
    "print(f'Average time outside of rush hour : {np.mean(binconts[[i for i in range(len(binconts)) if i not in index]]):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4e77a",
   "metadata": {},
   "source": [
    "#### Q. What about weekday vs. weekend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = np.array(start['day'])\n",
    "is_weekend = np.logical_and(day >= 5, day <= 6)\n",
    "\n",
    "fig = pl.figure(figsize=(11,8))\n",
    "frame1=fig.add_axes((.1,.3,.8,.6))\n",
    "h1=pl.hist(duration_min_2014[:int(data.shape[0]/20)][is_weekend==1], color='darkblue', density=True, bins=np.arange(1, 100),alpha=0.5,label=\"Weekend\")\n",
    "h2=pl.hist(duration_min_2014[:int(data.shape[0]/20)][is_weekend==0], color='darkred', density=True, bins=np.arange(1, 100),alpha=0.5,label=\"Weekday\")\n",
    "frame1.set_xticklabels([]) \n",
    "pl.grid()\n",
    "pl.ylabel('Density of Bike Trips')\n",
    "\n",
    "\n",
    "frame2=fig.add_axes((.1,.1,.8,.2))        \n",
    "pl.bar(h1[1][:-1],h1[0]-h2[0],width=1,color='k')\n",
    "grid()\n",
    "pl.ylabel('Difference')\n",
    "pl.xlabel('Duration (min)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c69079",
   "metadata": {},
   "source": [
    "#### Q. Where are BIXIs piling up? And where are they running out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = \\\n",
    "{\n",
    " 'Parc La Fontaine': (-73.570392, 45.527527),\n",
    " 'McGill': (-73.57722458691691, 45.504616238406314),  \n",
    " 'UdeM': (-73.61220069267776, 45.50681365964249),\n",
    " 'Mont Royal Chalet': (-73.58755377496506, 45.503930433540475)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,8))\n",
    "pl.scatter(stations['longitude'], stations['latitude'], s=10)\n",
    "\n",
    "for landmark in landmarks:\n",
    "    lon, lat = landmarks[landmark]\n",
    "    pl.scatter(lon, lat, marker='s', s=40, label=landmark)\n",
    "pl.grid()\n",
    "pl.ylabel('Lat (deg)')\n",
    "pl.xlabel('Lon (deg)')\n",
    "pl.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,8))\n",
    "hist, be1, be2, patches = pl.hist2d(stations['longitude'], stations['latitude'], bins=20)\n",
    "cbar=pl.colorbar()\n",
    "cbar.set_label('Density of Stations', rotation=270)\n",
    "\n",
    "pl.ylabel('Lat (deg)')\n",
    "pl.xlabel('Lon (deg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eea6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetest=np.arange(15,20)\n",
    "for d in datetest:\n",
    "    x=[]\n",
    "    y=[]\n",
    "    z=[]\n",
    "    for index, row in data.iterrows():\n",
    "        if (start['day'][index]==int(d)) and (start['month'][index]==4):\n",
    "            x.append(stations.loc[stations['code'] == row['start_station_code']]['longitude'].values[0])\n",
    "            y.append(stations.loc[stations['code'] == row['start_station_code']]['latitude'].values[0])\n",
    "            z.append(1)\n",
    "        \n",
    "            x.append(stations.loc[stations['code'] == row['end_station_code']]['longitude'].values[0])\n",
    "            y.append(stations.loc[stations['code'] == row['end_station_code']]['latitude'].values[0])\n",
    "            z.append(-1)\n",
    "        \n",
    "        if index > 100000:\n",
    "            break\n",
    "    pl.figure(figsize=(10,8))\n",
    "    pl.title(f'Date of {d}th of April 2014')\n",
    "    hist, be1, be2, patches = pl.hist2d(x,y,weights=z, bins=30,cmap='RdGy_r',vmin=-50,vmax=50)\n",
    "    \n",
    "    cbar=pl.colorbar()\n",
    "    cbar.set_label('Difference in Bikes', rotation=270)\n",
    "    pl.ylabel('Lat (deg)')\n",
    "    pl.xlabel('Lon (deg)')\n",
    "    for landmark in landmarks:\n",
    "        lon, lat = landmarks[landmark]\n",
    "        pl.scatter(lon, lat, marker='s', s=40, label=landmark)\n",
    "    pl.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf6641",
   "metadata": {},
   "source": [
    "#### What are the long term trends in the most active station like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73577c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "popstat=data.start_station_code.mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77fc198",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([0])\n",
    "y=np.array([0])\n",
    "for index, row in data.iterrows():\n",
    "    if row['start_station_code']==popstat:\n",
    "        x=np.append(x,datetime.datetime.strptime(data['start_date'][index], \"%Y-%m-%d %H:%M\"))\n",
    "        y=np.append(y,y[-1]+1)\n",
    "    if row['end_station_code']==popstat:\n",
    "        x=np.append(x,datetime.datetime.strptime(data['end_date'][index], \"%Y-%m-%d %H:%M\"))\n",
    "        y=np.append(y,y[-1]-1)\n",
    "    if index > 100000:\n",
    "        break\n",
    "x=np.delete(x,0)\n",
    "y=np.delete(y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y,'k-')\n",
    "plt.gcf().autofmt_xdate()\n",
    "dtFmt = mdates.DateFormatter('%D-%H:%M') \n",
    "plt.gca().xaxis.set_major_formatter(dtFmt) \n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Change in Bikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766fea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "def sin_func(x, a, b,c):\n",
    "    return a * np.sin(x*b*(2*np.pi))+c\n",
    "xdiff=np.zeros(len(x))\n",
    "for i in range(len(x)):\n",
    "    xdiff[i]=(x[i]-x[0]).total_seconds()\n",
    "par, parcov = optimize.curve_fit(sin_func, xdiff, y,p0=[10,1e-5,-23])\n",
    "print(par)\n",
    "print(parcov)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(xdiff,y,'k-')\n",
    "xdense=np.arange(0,xdiff[-1],100)\n",
    "plt.plot(xdense,sin_func(xdense,10,1e-5,-23),label='Starting Parameters')\n",
    "plt.plot(xdense,sin_func(xdense,*par),label='Best-Fit Parameters')\n",
    "\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Change in Bikes')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "from scipy import interpolate\n",
    "f = interpolate.interp1d(xdiff, y)\n",
    "\n",
    "time_step = xdense[1]-xdense[0]\n",
    "yinterp=f(xdense)\n",
    "\n",
    "\n",
    "freqs = np.fft.rfftfreq(yinterp.size, time_step)\n",
    "idx = np.argsort(yinterp)\n",
    "ps = np.abs(np.fft.rfft(yinterp-np.mean(yinterp)))**2\n",
    "\n",
    "plt.plot(freqs[1:], ps[1:],color='k')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power ')\n",
    "plt.axvline(1/86400.,label='1/day')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5c4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
